{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c154aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "061de43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneeKeypointDataset(Dataset):\n",
    "    \"\"\"Dataset for loading knee point clouds and keypoint annotations.\"\"\"\n",
    "    \n",
    "    def __init__(self, json_file: str, pointcloud_dir: str, max_points: int = 8192, \n",
    "                 surface_sampling_method: str = 'uniform'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file: Path to JSON file with keypoint annotations\n",
    "            pointcloud_dir: Directory containing STL mesh files\n",
    "            max_points: Maximum number of points to sample from each mesh\n",
    "            surface_sampling_method: 'uniform' or 'poisson' for surface sampling\n",
    "        \"\"\"\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        self.pointcloud_dir = pointcloud_dir\n",
    "        self.max_points = max_points\n",
    "        self.sampling_method = surface_sampling_method\n",
    "        \n",
    "        # Expected 5 keypoints: front, left, right, thigh_center, shin_center\n",
    "        self.keypoint_names = ['front', 'left', 'right', 'thigh_center', 'shin_center']\n",
    "        self.num_keypoints = len(self.keypoint_names)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def load_point_cloud(self, model_id: str) -> np.ndarray:\n",
    "        \"\"\"Load mesh from STL file and sample points from surface.\"\"\"\n",
    "        mesh_path = os.path.join(self.pointcloud_dir, f\"{model_id}.stl\")\n",
    "        \n",
    "        # Load mesh from STL file\n",
    "        mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "        \n",
    "        # Check if mesh is valid\n",
    "        if len(mesh.vertices) == 0:\n",
    "            raise ValueError(f\"Failed to load mesh from {mesh_path}\")\n",
    "        \n",
    "        # Sample points from mesh surface\n",
    "        # Use more points than needed for better coverage\n",
    "        num_sample_points = self.max_points * 2  # Sample more than we need\n",
    "        \n",
    "        # Method 1: Uniform sampling\n",
    "        pcd = mesh.sample_points_uniformly(number_of_points=num_sample_points)\n",
    "        \n",
    "        # Alternative method 2: Poisson disk sampling (more even distribution)\n",
    "        # pcd = mesh.sample_points_poisson_disk(number_of_points=num_sample_points)\n",
    "        \n",
    "        points = np.asarray(pcd.points)\n",
    "        \n",
    "        # If we didn't get enough points, use fewer\n",
    "        if len(points) < self.max_points:\n",
    "            print(f\"Warning: Only sampled {len(points)} points from mesh {model_id}\")\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def find_nearest_point_indices(self, points: np.ndarray, keypoint_coords: List[List[float]]) -> List[int]:\n",
    "        \"\"\"Find nearest point indices for each keypoint coordinate.\"\"\"\n",
    "        # Use KNN to find nearest points\n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(points)\n",
    "        \n",
    "        keypoint_indices = []\n",
    "        for coord in keypoint_coords:\n",
    "            distances, indices = nbrs.kneighbors([coord])\n",
    "            keypoint_indices.append(indices[0][0])\n",
    "        \n",
    "        return keypoint_indices\n",
    "    \n",
    "    def normalize_point_cloud(self, points: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize point cloud to unit sphere.\"\"\"\n",
    "        # Center the point cloud\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        points = points - centroid\n",
    "        \n",
    "        # Scale to unit sphere\n",
    "        max_distance = np.max(np.linalg.norm(points, axis=1))\n",
    "        points = points / max_distance\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def sample_points(self, points: np.ndarray, keypoint_indices: List[int]) -> Tuple[np.ndarray, List[int]]:\n",
    "        \"\"\"Sample points while preserving keypoint indices.\"\"\"\n",
    "        n_points = len(points)\n",
    "        \n",
    "        if n_points <= self.max_points:\n",
    "            # Pad with zeros if needed\n",
    "            padded_points = np.zeros((self.max_points, 3))\n",
    "            padded_points[:n_points] = points\n",
    "            return padded_points, keypoint_indices\n",
    "        \n",
    "        # Always include keypoint indices in sampling\n",
    "        keypoint_set = set(keypoint_indices)\n",
    "        non_keypoint_indices = [i for i in range(n_points) if i not in keypoint_set]\n",
    "        \n",
    "        # Sample remaining points\n",
    "        n_additional = self.max_points - len(keypoint_indices)\n",
    "        if n_additional > 0:\n",
    "            sampled_indices = np.random.choice(\n",
    "                non_keypoint_indices, \n",
    "                size=min(n_additional, len(non_keypoint_indices)), \n",
    "                replace=False\n",
    "            )\n",
    "            all_indices = list(keypoint_indices) + list(sampled_indices)\n",
    "        else:\n",
    "            all_indices = keypoint_indices\n",
    "        \n",
    "        # Create mapping from old to new indices\n",
    "        old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(all_indices)}\n",
    "        new_keypoint_indices = [old_to_new[idx] for idx in keypoint_indices]\n",
    "        \n",
    "        return points[all_indices], new_keypoint_indices\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        annotation = self.annotations[idx]\n",
    "        model_id = annotation['model_id']\n",
    "        \n",
    "        # Load point cloud\n",
    "        points = self.load_point_cloud(model_id)\n",
    "        \n",
    "        # Extract keypoint coordinates\n",
    "        keypoint_coords = [kp['xyz'] for kp in annotation['keypoints']]\n",
    "        \n",
    "        # Find nearest point indices\n",
    "        keypoint_indices = self.find_nearest_point_indices(points, keypoint_coords)\n",
    "        \n",
    "        # Normalize point cloud\n",
    "        points = self.normalize_point_cloud(points)\n",
    "        \n",
    "        # Sample points\n",
    "        points, keypoint_indices = self.sample_points(points, keypoint_indices)\n",
    "        \n",
    "        # Create keypoint labels (one-hot encoded)\n",
    "        keypoint_labels = np.zeros((self.num_keypoints, len(points)))\n",
    "        for i, idx in enumerate(keypoint_indices):\n",
    "            if idx < len(points):  # Safety check\n",
    "                keypoint_labels[i, idx] = 1\n",
    "        \n",
    "        return {\n",
    "            'points': torch.FloatTensor(points),\n",
    "            'keypoint_labels': torch.FloatTensor(keypoint_labels),\n",
    "            'model_id': model_id\n",
    "        }\n",
    "\n",
    "\n",
    "class PointNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"PointNet feature extractor for point cloud processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 3, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Point-wise MLPs\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(feature_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 3, num_points)\n",
    "        batch_size, _, num_points = x.size()\n",
    "        \n",
    "        # Point-wise feature extraction\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global feature\n",
    "        global_feature = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Concatenate global and local features\n",
    "        global_feature = global_feature.repeat(1, 1, num_points)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class KneeKeypointModel(nn.Module):\n",
    "    \"\"\"Multi-task model for knee keypoint detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoints: int = 5, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.feature_extractor = PointNetFeatureExtractor(feature_dim=feature_dim)\n",
    "        \n",
    "        # Feature dimension after concatenation\n",
    "        concat_dim = feature_dim * 2\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared_conv1 = nn.Conv1d(concat_dim, 512, 1)\n",
    "        self.shared_conv2 = nn.Conv1d(512, 256, 1)\n",
    "        self.shared_bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared_bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Keypoint-specific heads\n",
    "        self.keypoint_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 128, 1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Conv1d(128, 1, 1)\n",
    "            ) for _ in range(num_keypoints)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_points, 3)\n",
    "        batch_size, num_points, _ = x.size()\n",
    "        \n",
    "        # Transpose for conv1d\n",
    "        x = x.transpose(2, 1)  # (batch, 3, num_points)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Shared processing\n",
    "        x = F.relu(self.shared_bn1(self.shared_conv1(features)))\n",
    "        x = F.relu(self.shared_bn2(self.shared_conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Keypoint predictions\n",
    "        keypoint_outputs = []\n",
    "        for head in self.keypoint_heads:\n",
    "            output = head(x)  # (batch, 1, num_points)\n",
    "            output = output.squeeze(1)  # (batch, num_points)\n",
    "            keypoint_outputs.append(output)\n",
    "        \n",
    "        return torch.stack(keypoint_outputs, dim=1)  # (batch, num_keypoints, num_points)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal loss for handling class imbalance.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: (batch, num_keypoints, num_points)\n",
    "        # targets: (batch, num_keypoints, num_points)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(inputs, dim=-1)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        ce_loss = F.cross_entropy(inputs.view(-1, inputs.size(-1)), \n",
    "                                 targets.argmax(dim=-1).view(-1), \n",
    "                                 reduction='none')\n",
    "        \n",
    "        # Get probabilities of true class\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ebcd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs: int = 100, \n",
    "                learning_rate: float = 0.001, device: str = 'cuda'):\n",
    "    \"\"\"Training loop for the keypoint detection model.\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = FocalLoss(alpha=1.0, gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(points)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                points = batch['points'].to(device)\n",
    "                labels = batch['keypoint_labels'].to(device)\n",
    "                \n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_knee_keypoint_model.pth')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device: str = 'cuda'):\n",
    "    \"\"\"Evaluate the model and compute keypoint detection accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_distance_error = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "            \n",
    "            outputs = model(points)\n",
    "            \n",
    "            # Get predicted keypoint indices\n",
    "            pred_indices = torch.argmax(outputs, dim=-1)  # (batch, num_keypoints)\n",
    "            true_indices = torch.argmax(labels, dim=-1)   # (batch, num_keypoints)\n",
    "            \n",
    "            # Compute distance error\n",
    "            batch_size = points.size(0)\n",
    "            for i in range(batch_size):\n",
    "                for j in range(model.num_keypoints):\n",
    "                    pred_point = points[i, pred_indices[i, j]]\n",
    "                    true_point = points[i, true_indices[i, j]]\n",
    "                    distance = torch.norm(pred_point - true_point).item()\n",
    "                    total_distance_error += distance\n",
    "                    total_samples += 1\n",
    "    \n",
    "    avg_distance_error = total_distance_error / total_samples\n",
    "    print(f'Average keypoint distance error: {avg_distance_error:.4f}')\n",
    "    \n",
    "    return avg_distance_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1c7202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = KneeKeypointDataset(\n",
    "    json_file='knee_annotations/7-2-25/knee_points_4_5_flipped.json',\n",
    "    pointcloud_dir='scans_3/',\n",
    "    max_points=8192\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8375b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f725df00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = KneeKeypointModel(num_keypoints=5)\n",
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b497452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 9.0211\n",
      "Epoch 0: Train Loss: 8.8080, Val Loss: 8.9963\n",
      "Epoch 1, Batch 0, Loss: 8.7484\n",
      "Epoch 1: Train Loss: 8.5513, Val Loss: 8.9119\n",
      "Epoch 2, Batch 0, Loss: 8.3399\n",
      "Epoch 2: Train Loss: 8.3537, Val Loss: 8.7145\n",
      "Epoch 3, Batch 0, Loss: 8.0789\n",
      "Epoch 3: Train Loss: 8.2572, Val Loss: 8.6199\n",
      "Epoch 4, Batch 0, Loss: 8.0896\n",
      "Epoch 4: Train Loss: 8.0814, Val Loss: 8.1946\n",
      "Epoch 5, Batch 0, Loss: 7.5723\n",
      "Epoch 5: Train Loss: 7.8103, Val Loss: 8.0154\n",
      "Epoch 6, Batch 0, Loss: 7.5653\n",
      "Epoch 6: Train Loss: 7.8511, Val Loss: 7.9865\n",
      "Epoch 7, Batch 0, Loss: 7.4185\n",
      "Epoch 7: Train Loss: 8.0430, Val Loss: 7.9969\n",
      "Epoch 8, Batch 0, Loss: 7.3675\n",
      "Epoch 8: Train Loss: 7.5014, Val Loss: 8.0364\n",
      "Epoch 9, Batch 0, Loss: 7.4411\n",
      "Epoch 9: Train Loss: 7.6627, Val Loss: 7.9548\n",
      "Epoch 10, Batch 0, Loss: 7.0541\n",
      "Epoch 10: Train Loss: 7.4648, Val Loss: 7.6892\n",
      "Epoch 11, Batch 0, Loss: 6.9380\n",
      "Epoch 11: Train Loss: 7.5327, Val Loss: 7.9900\n",
      "Epoch 12, Batch 0, Loss: 7.3837\n",
      "Epoch 12: Train Loss: 7.1681, Val Loss: 7.9379\n",
      "Epoch 13, Batch 0, Loss: 6.7256\n",
      "Epoch 13: Train Loss: 6.8933, Val Loss: 7.6507\n",
      "Epoch 14, Batch 0, Loss: 6.8440\n",
      "Epoch 14: Train Loss: 7.1268, Val Loss: 8.1049\n",
      "Epoch 15, Batch 0, Loss: 6.5596\n",
      "Epoch 15: Train Loss: 7.4449, Val Loss: 7.7013\n",
      "Epoch 16, Batch 0, Loss: 6.5457\n",
      "Epoch 16: Train Loss: 7.1606, Val Loss: 7.8611\n",
      "Epoch 17, Batch 0, Loss: 6.8587\n",
      "Epoch 17: Train Loss: 7.3431, Val Loss: 7.4289\n",
      "Epoch 18, Batch 0, Loss: 6.5667\n",
      "Epoch 18: Train Loss: 7.1333, Val Loss: 7.5749\n",
      "Epoch 19, Batch 0, Loss: 6.7856\n",
      "Epoch 19: Train Loss: 6.6379, Val Loss: 7.1527\n",
      "Epoch 20, Batch 0, Loss: 6.2859\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m evaluate_model(trained_model, val_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     20\u001b[0m     points \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoint_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/utils/data/dataset.py:416\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/pointnet_env/lib/python3.10/site-packages/torch/utils/data/dataset.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[17], line 117\u001b[0m, in \u001b[0;36mKneeKeypointDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    114\u001b[0m model_id \u001b[38;5;241m=\u001b[39m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Load point cloud\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_point_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Extract keypoint coordinates\u001b[39;00m\n\u001b[1;32m    120\u001b[0m keypoint_coords \u001b[38;5;241m=\u001b[39m [kp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxyz\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m kp \u001b[38;5;129;01min\u001b[39;00m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[17], line 32\u001b[0m, in \u001b[0;36mKneeKeypointDataset.load_point_cloud\u001b[0;34m(self, model_id)\u001b[0m\n\u001b[1;32m     29\u001b[0m mesh_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointcloud_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.stl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Load mesh from STL file\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mo3d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_triangle_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Check if mesh is valid\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mesh\u001b[38;5;241m.\u001b[39mvertices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, train_loader, val_loader, device=device)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(trained_model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e238a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a7851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66066a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
