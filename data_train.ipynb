{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c154aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061de43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneeKeypointDataset(Dataset):\n",
    "    \"\"\"Dataset for loading knee point clouds and keypoint annotations.\"\"\"\n",
    "    \n",
    "    def __init__(self, json_file: str, pointcloud_dir: str, max_points: int = 8192):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file: Path to JSON file with keypoint annotations\n",
    "            pointcloud_dir: Directory containing point cloud files\n",
    "            max_points: Maximum number of points to sample from each point cloud\n",
    "        \"\"\"\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        self.pointcloud_dir = pointcloud_dir\n",
    "        self.max_points = max_points\n",
    "        \n",
    "        # Expected 5 keypoints: front, left, right, thigh_center, shin_center\n",
    "        self.keypoint_names = ['front', 'left', 'right', 'thigh_center', 'shin_center']\n",
    "        self.num_keypoints = len(self.keypoint_names)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def load_point_cloud(self, model_id: str) -> np.ndarray:\n",
    "        \"\"\"Load point cloud from file. Assumes PLY format.\"\"\"\n",
    "        # Adjust file extension and loading method based on your format\n",
    "        #pc_path = os.path.join(self.pointcloud_dir, f\"{model_id}.ply\")\n",
    "        pc_path = os.path.join(self.pointcloud_dir, f\"{model_id}.stl\")\n",
    "        \n",
    "        # Using open3d for PLY files\n",
    "        pcd = o3d.io.read_point_cloud(pc_path)\n",
    "        points = np.asarray(pcd.points)\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def find_nearest_point_indices(self, points: np.ndarray, keypoint_coords: List[List[float]]) -> List[int]:\n",
    "        \"\"\"Find nearest point indices for each keypoint coordinate.\"\"\"\n",
    "        # Use KNN to find nearest points\n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(points)\n",
    "        \n",
    "        keypoint_indices = []\n",
    "        for coord in keypoint_coords:\n",
    "            distances, indices = nbrs.kneighbors([coord])\n",
    "            keypoint_indices.append(indices[0][0])\n",
    "        \n",
    "        return keypoint_indices\n",
    "    \n",
    "    def normalize_point_cloud(self, points: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize point cloud to unit sphere.\"\"\"\n",
    "        # Center the point cloud\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        points = points - centroid\n",
    "        \n",
    "        # Scale to unit sphere\n",
    "        max_distance = np.max(np.linalg.norm(points, axis=1))\n",
    "        points = points / max_distance\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def sample_points(self, points: np.ndarray, keypoint_indices: List[int]) -> Tuple[np.ndarray, List[int]]:\n",
    "        \"\"\"Sample points while preserving keypoint indices.\"\"\"\n",
    "        n_points = len(points)\n",
    "        \n",
    "        if n_points <= self.max_points:\n",
    "            # Pad with zeros if needed\n",
    "            padded_points = np.zeros((self.max_points, 3))\n",
    "            padded_points[:n_points] = points\n",
    "            return padded_points, keypoint_indices\n",
    "        \n",
    "        # Always include keypoint indices in sampling\n",
    "        keypoint_set = set(keypoint_indices)\n",
    "        non_keypoint_indices = [i for i in range(n_points) if i not in keypoint_set]\n",
    "        \n",
    "        # Sample remaining points\n",
    "        n_additional = self.max_points - len(keypoint_indices)\n",
    "        if n_additional > 0:\n",
    "            sampled_indices = np.random.choice(\n",
    "                non_keypoint_indices, \n",
    "                size=min(n_additional, len(non_keypoint_indices)), \n",
    "                replace=False\n",
    "            )\n",
    "            all_indices = list(keypoint_indices) + list(sampled_indices)\n",
    "        else:\n",
    "            all_indices = keypoint_indices\n",
    "        \n",
    "        # Create mapping from old to new indices\n",
    "        old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(all_indices)}\n",
    "        new_keypoint_indices = [old_to_new[idx] for idx in keypoint_indices]\n",
    "        \n",
    "        return points[all_indices], new_keypoint_indices\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        annotation = self.annotations[idx]\n",
    "        model_id = annotation['model_id']\n",
    "        \n",
    "        # Load point cloud\n",
    "        points = self.load_point_cloud(model_id)\n",
    "        \n",
    "        # Extract keypoint coordinates\n",
    "        keypoint_coords = [kp['xyz'] for kp in annotation['keypoints']]\n",
    "        \n",
    "        # Find nearest point indices\n",
    "        keypoint_indices = self.find_nearest_point_indices(points, keypoint_coords)\n",
    "        \n",
    "        # Normalize point cloud\n",
    "        points = self.normalize_point_cloud(points)\n",
    "        \n",
    "        # Sample points\n",
    "        points, keypoint_indices = self.sample_points(points, keypoint_indices)\n",
    "        \n",
    "        # Create keypoint labels (one-hot encoded)\n",
    "        keypoint_labels = np.zeros((self.num_keypoints, len(points)))\n",
    "        for i, idx in enumerate(keypoint_indices):\n",
    "            if idx < len(points):  # Safety check\n",
    "                keypoint_labels[i, idx] = 1\n",
    "        \n",
    "        return {\n",
    "            'points': torch.FloatTensor(points),\n",
    "            'keypoint_labels': torch.FloatTensor(keypoint_labels),\n",
    "            'model_id': model_id\n",
    "        }\n",
    "\n",
    "\n",
    "class PointNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"PointNet feature extractor for point cloud processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 3, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Point-wise MLPs\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(feature_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 3, num_points)\n",
    "        batch_size, _, num_points = x.size()\n",
    "        \n",
    "        # Point-wise feature extraction\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global feature\n",
    "        global_feature = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Concatenate global and local features\n",
    "        global_feature = global_feature.repeat(1, 1, num_points)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class KneeKeypointModel(nn.Module):\n",
    "    \"\"\"Multi-task model for knee keypoint detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoints: int = 5, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.feature_extractor = PointNetFeatureExtractor(feature_dim=feature_dim)\n",
    "        \n",
    "        # Feature dimension after concatenation\n",
    "        concat_dim = feature_dim * 2\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared_conv1 = nn.Conv1d(concat_dim, 512, 1)\n",
    "        self.shared_conv2 = nn.Conv1d(512, 256, 1)\n",
    "        self.shared_bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared_bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Keypoint-specific heads\n",
    "        self.keypoint_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 128, 1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Conv1d(128, 1, 1)\n",
    "            ) for _ in range(num_keypoints)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_points, 3)\n",
    "        batch_size, num_points, _ = x.size()\n",
    "        \n",
    "        # Transpose for conv1d\n",
    "        x = x.transpose(2, 1)  # (batch, 3, num_points)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Shared processing\n",
    "        x = F.relu(self.shared_bn1(self.shared_conv1(features)))\n",
    "        x = F.relu(self.shared_bn2(self.shared_conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Keypoint predictions\n",
    "        keypoint_outputs = []\n",
    "        for head in self.keypoint_heads:\n",
    "            output = head(x)  # (batch, 1, num_points)\n",
    "            output = output.squeeze(1)  # (batch, num_points)\n",
    "            keypoint_outputs.append(output)\n",
    "        \n",
    "        return torch.stack(keypoint_outputs, dim=1)  # (batch, num_keypoints, num_points)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal loss for handling class imbalance.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: (batch, num_keypoints, num_points)\n",
    "        # targets: (batch, num_keypoints, num_points)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(inputs, dim=-1)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        ce_loss = F.cross_entropy(inputs.view(-1, inputs.size(-1)), \n",
    "                                 targets.argmax(dim=-1).view(-1), \n",
    "                                 reduction='none')\n",
    "        \n",
    "        # Get probabilities of true class\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ebcd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs: int = 100, \n",
    "                learning_rate: float = 0.001, device: str = 'cuda'):\n",
    "    \"\"\"Training loop for the keypoint detection model.\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = FocalLoss(alpha=1.0, gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(points)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                points = batch['points'].to(device)\n",
    "                labels = batch['keypoint_labels'].to(device)\n",
    "                \n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_knee_keypoint_model.pth')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device: str = 'cuda'):\n",
    "    \"\"\"Evaluate the model and compute keypoint detection accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_distance_error = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "            \n",
    "            outputs = model(points)\n",
    "            \n",
    "            # Get predicted keypoint indices\n",
    "            pred_indices = torch.argmax(outputs, dim=-1)  # (batch, num_keypoints)\n",
    "            true_indices = torch.argmax(labels, dim=-1)   # (batch, num_keypoints)\n",
    "            \n",
    "            # Compute distance error\n",
    "            batch_size = points.size(0)\n",
    "            for i in range(batch_size):\n",
    "                for j in range(model.num_keypoints):\n",
    "                    pred_point = points[i, pred_indices[i, j]]\n",
    "                    true_point = points[i, true_indices[i, j]]\n",
    "                    distance = torch.norm(pred_point - true_point).item()\n",
    "                    total_distance_error += distance\n",
    "                    total_samples += 1\n",
    "    \n",
    "    avg_distance_error = total_distance_error / total_samples\n",
    "    print(f'Average keypoint distance error: {avg_distance_error:.4f}')\n",
    "    \n",
    "    return avg_distance_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b497452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset\n",
    "dataset = KneeKeypointDataset(\n",
    "    json_file='knee_annotations/7-2-25/knee_points_4_5_flipped.json',\n",
    "    pointcloud_dir='scans_3/',\n",
    "    max_points=8192\n",
    ")\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = KneeKeypointModel(num_keypoints=5)\n",
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "trained_model = train_model(model, train_loader, val_loader, device=device)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(trained_model, val_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e238a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a7851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66066a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
