{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40e9d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c3225f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneeKeypointDataset(Dataset):\n",
    "    \"\"\"Dataset for loading knee point clouds and keypoint annotations.\"\"\"\n",
    "    \n",
    "    def __init__(self, json_file: str, pointcloud_dir: str, max_points: int = 8192, \n",
    "                 surface_sampling_method: str = 'uniform', num_keypoints: int = 5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_file: Path to JSON file with keypoint annotations\n",
    "            pointcloud_dir: Directory containing STL mesh files\n",
    "            max_points: Maximum number of points to sample from each mesh\n",
    "            surface_sampling_method: 'uniform' or 'poisson' for surface sampling\n",
    "            num_keypoints: Number of keypoints to use (useful for data cleaning with fewer keypoints)\n",
    "        \"\"\"\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        self.pointcloud_dir = pointcloud_dir\n",
    "        self.max_points = max_points\n",
    "        self.sampling_method = surface_sampling_method\n",
    "        self.num_keypoints = num_keypoints\n",
    "        \n",
    "        # Validate that annotations have the expected number of keypoints\n",
    "        if len(self.annotations) > 0:\n",
    "            expected_keypoints = len(self.annotations[0]['keypoints'])\n",
    "            if expected_keypoints != num_keypoints:\n",
    "                print(f\"Warning: Expected {num_keypoints} keypoints but found {expected_keypoints} in annotation file\")\n",
    "        \n",
    "        # Default keypoint names (you can modify these based on your specific needs)\n",
    "        self.keypoint_names = ['front', 'left', 'right', 'thigh_center', 'shin_center'][:num_keypoints]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def load_point_cloud(self, model_id: str) -> np.ndarray:\n",
    "        \"\"\"Load mesh from STL file and sample points from surface.\"\"\"\n",
    "        mesh_path = os.path.join(self.pointcloud_dir, f\"{model_id}.stl\")\n",
    "        \n",
    "        # Load mesh from STL file\n",
    "        mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "        \n",
    "        # Check if mesh is valid\n",
    "        if len(mesh.vertices) == 0:\n",
    "            raise ValueError(f\"Failed to load mesh from {mesh_path}\")\n",
    "        \n",
    "        # Sample points from mesh surface\n",
    "        # Use more points than needed for better coverage\n",
    "        num_sample_points = self.max_points * 2  # Sample more than we need\n",
    "        \n",
    "        # Method 1: Uniform sampling\n",
    "        pcd = mesh.sample_points_uniformly(number_of_points=num_sample_points)\n",
    "        \n",
    "        # Alternative method 2: Poisson disk sampling (more even distribution)\n",
    "        # pcd = mesh.sample_points_poisson_disk(number_of_points=num_sample_points)\n",
    "        \n",
    "        points = np.asarray(pcd.points)\n",
    "        \n",
    "        # If we didn't get enough points, use fewer\n",
    "        if len(points) < self.max_points:\n",
    "            print(f\"Warning: Only sampled {len(points)} points from mesh {model_id}\")\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def find_nearest_point_indices(self, points: np.ndarray, keypoint_coords: List[List[float]]) -> List[int]:\n",
    "        \"\"\"Find nearest point indices for each keypoint coordinate.\"\"\"\n",
    "        # Use KNN to find nearest points\n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(points)\n",
    "        \n",
    "        keypoint_indices = []\n",
    "        for coord in keypoint_coords:\n",
    "            distances, indices = nbrs.kneighbors([coord])\n",
    "            keypoint_indices.append(indices[0][0])\n",
    "        \n",
    "        return keypoint_indices\n",
    "    \n",
    "    def normalize_point_cloud(self, points: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Normalize point cloud to unit sphere.\"\"\"\n",
    "        # Center the point cloud\n",
    "        centroid = np.mean(points, axis=0)\n",
    "        points = points - centroid\n",
    "        \n",
    "        # Scale to unit sphere\n",
    "        max_distance = np.max(np.linalg.norm(points, axis=1))\n",
    "        points = points / max_distance\n",
    "        \n",
    "        return points\n",
    "    \n",
    "    def sample_points(self, points: np.ndarray, keypoint_indices: List[int]) -> Tuple[np.ndarray, List[int]]:\n",
    "        \"\"\"Sample points while preserving keypoint indices.\"\"\"\n",
    "        n_points = len(points)\n",
    "        \n",
    "        if n_points <= self.max_points:\n",
    "            # Pad with zeros if needed\n",
    "            padded_points = np.zeros((self.max_points, 3))\n",
    "            padded_points[:n_points] = points\n",
    "            return padded_points, keypoint_indices\n",
    "        \n",
    "        # Always include keypoint indices in sampling\n",
    "        keypoint_set = set(keypoint_indices)\n",
    "        non_keypoint_indices = [i for i in range(n_points) if i not in keypoint_set]\n",
    "        \n",
    "        # Sample remaining points\n",
    "        n_additional = self.max_points - len(keypoint_indices)\n",
    "        if n_additional > 0:\n",
    "            sampled_indices = np.random.choice(\n",
    "                non_keypoint_indices, \n",
    "                size=min(n_additional, len(non_keypoint_indices)), \n",
    "                replace=False\n",
    "            )\n",
    "            all_indices = list(keypoint_indices) + list(sampled_indices)\n",
    "        else:\n",
    "            all_indices = keypoint_indices\n",
    "        \n",
    "        # Create mapping from old to new indices\n",
    "        old_to_new = {old_idx: new_idx for new_idx, old_idx in enumerate(all_indices)}\n",
    "        new_keypoint_indices = [old_to_new[idx] for idx in keypoint_indices]\n",
    "        \n",
    "        return points[all_indices], new_keypoint_indices\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        annotation = self.annotations[idx]\n",
    "        model_id = annotation['model_id']\n",
    "        \n",
    "        # Load point cloud\n",
    "        points = self.load_point_cloud(model_id)\n",
    "        \n",
    "        # Extract keypoint coordinates (only use the first num_keypoints)\n",
    "        keypoint_coords = [kp['xyz'] for kp in annotation['keypoints'][:self.num_keypoints]]\n",
    "        \n",
    "        # Find nearest point indices\n",
    "        keypoint_indices = self.find_nearest_point_indices(points, keypoint_coords)\n",
    "        \n",
    "        # Normalize point cloud\n",
    "        points = self.normalize_point_cloud(points)\n",
    "        \n",
    "        # Sample points\n",
    "        points, keypoint_indices = self.sample_points(points, keypoint_indices)\n",
    "        \n",
    "        # Create keypoint labels (one-hot encoded)\n",
    "        keypoint_labels = np.zeros((self.num_keypoints, len(points)))\n",
    "        for i, idx in enumerate(keypoint_indices):\n",
    "            if idx < len(points):  # Safety check\n",
    "                keypoint_labels[i, idx] = 1\n",
    "        \n",
    "        return {\n",
    "            'points': torch.FloatTensor(points),\n",
    "            'keypoint_labels': torch.FloatTensor(keypoint_labels),\n",
    "            'model_id': model_id\n",
    "        }\n",
    "\n",
    "\n",
    "class PointNetFeatureExtractor(nn.Module):\n",
    "    \"\"\"PointNet feature extractor for point cloud processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 3, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Point-wise MLPs\n",
    "        self.conv1 = nn.Conv1d(input_dim, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, feature_dim, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(feature_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, 3, num_points)\n",
    "        batch_size, _, num_points = x.size()\n",
    "        \n",
    "        # Point-wise feature extraction\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Global feature\n",
    "        global_feature = torch.max(x, 2, keepdim=True)[0]\n",
    "        \n",
    "        # Concatenate global and local features\n",
    "        global_feature = global_feature.repeat(1, 1, num_points)\n",
    "        x = torch.cat([x, global_feature], dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class KneeKeypointModel(nn.Module):\n",
    "    \"\"\"Multi-task model for knee keypoint detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoints: int = 5, feature_dim: int = 1024):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.feature_extractor = PointNetFeatureExtractor(feature_dim=feature_dim)\n",
    "        \n",
    "        # Feature dimension after concatenation\n",
    "        concat_dim = feature_dim * 2\n",
    "        \n",
    "        # Shared layers\n",
    "        self.shared_conv1 = nn.Conv1d(concat_dim, 512, 1)\n",
    "        self.shared_conv2 = nn.Conv1d(512, 256, 1)\n",
    "        self.shared_bn1 = nn.BatchNorm1d(512)\n",
    "        self.shared_bn2 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        # Keypoint-specific heads\n",
    "        self.keypoint_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv1d(256, 128, 1),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Conv1d(128, 1, 1)\n",
    "            ) for _ in range(num_keypoints)\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, num_points, 3)\n",
    "        batch_size, num_points, _ = x.size()\n",
    "        \n",
    "        # Transpose for conv1d\n",
    "        x = x.transpose(2, 1)  # (batch, 3, num_points)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # Shared processing\n",
    "        x = F.relu(self.shared_bn1(self.shared_conv1(features)))\n",
    "        x = F.relu(self.shared_bn2(self.shared_conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Keypoint predictions\n",
    "        keypoint_outputs = []\n",
    "        for head in self.keypoint_heads:\n",
    "            output = head(x)  # (batch, 1, num_points)\n",
    "            output = output.squeeze(1)  # (batch, num_points)\n",
    "            keypoint_outputs.append(output)\n",
    "        \n",
    "        return torch.stack(keypoint_outputs, dim=1)  # (batch, num_keypoints, num_points)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal loss for handling class imbalance.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: (batch, num_keypoints, num_points)\n",
    "        # targets: (batch, num_keypoints, num_points)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        #probs = F.softmax(inputs, dim=-1) #Not used anywhere...\n",
    "        \n",
    "        # Compute focal loss\n",
    "        ce_loss = F.cross_entropy(inputs.view(-1, inputs.size(-1)), \n",
    "                                 targets.argmax(dim=-1).view(-1), \n",
    "                                 reduction='none')\n",
    "        \n",
    "        # Get probabilities of true class\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        # Compute focal loss\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8a83eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, \n",
    "                train_loader, \n",
    "                val_loader, \n",
    "                num_epochs: int = 100,\n",
    "                learning_rate: float = 0.001, \n",
    "                device: str = 'cuda',\n",
    "                weight_decay: float = 1e-4,\n",
    "                focal_alpha: float = 1.0,\n",
    "                focal_gamma: float = 2.0,\n",
    "                save_path: str = 'best_knee_keypoint_model.pth',\n",
    "                checkpoint_path: str = 'checkpoint.pth',\n",
    "                load_path: str = 'best_knee_keypoint_model.pth',\n",
    "                resume: bool = False):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Resume logic\n",
    "    if resume and os.path.exists(load_path):\n",
    "        print(\"Resuming Training From Checkpoint Saved at: \", load_path)\n",
    "        checkpoint = torch.load(load_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_loss = checkpoint['best_val_loss']\n",
    "        print(\"Loading Checkpoint with best val loss: \", best_val_loss)\n",
    "        print(f\"[INFO] Resumed training from epoch {start_epoch}\")\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(points)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch}/{num_epochs}] Batch [{batch_idx}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                points = batch['points'].to(device)\n",
    "                labels = batch['keypoint_labels'].to(device)\n",
    "                outputs = model(points)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save best model separately\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "             \n",
    "             \n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_loss': best_val_loss\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_path) # save checkpoint\n",
    "            print(f\"[INFO] Checkpoint saved at epoch {epoch} with val loss {best_val_loss:.4f} at location: {checkpoint_path}\")\n",
    "          \n",
    "            torch.save(model.state_dict(), save_path) # save model\n",
    "            print(f\"[INFO] Best model saved at epoch {epoch} with val loss {best_val_loss:.4f} at location: {save_path}\")\n",
    "\n",
    "        # Save checkpoint every 20th epoch\n",
    "        if epoch + 1 % 20 == 0:\n",
    "            print(\"Saving period checkpoint at epoch: \", epoch)\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_loss': best_val_loss\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_path[:-4] + f\"-{epoch}.pth\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Load best weights before returning\n",
    "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
    "    print(f\"[INFO] Training completed. Best model loaded from {save_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device: str = 'cuda'):\n",
    "    \"\"\"Evaluate the model and compute keypoint detection accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_distance_error = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            points = batch['points'].to(device)\n",
    "            labels = batch['keypoint_labels'].to(device)\n",
    "            \n",
    "            outputs = model(points)\n",
    "            \n",
    "            # Get predicted keypoint indices\n",
    "            pred_indices = torch.argmax(outputs, dim=-1)  # (batch, num_keypoints)\n",
    "            true_indices = torch.argmax(labels, dim=-1)   # (batch, num_keypoints)\n",
    "            \n",
    "            # Compute distance error\n",
    "            batch_size = points.size(0)\n",
    "            for i in range(batch_size):\n",
    "                for j in range(model.num_keypoints):\n",
    "                    pred_point = points[i, pred_indices[i, j]]\n",
    "                    true_point = points[i, true_indices[i, j]]\n",
    "                    distance = torch.norm(pred_point - true_point).item()\n",
    "                    total_distance_error += distance\n",
    "                    total_samples += 1\n",
    "    \n",
    "    avg_distance_error = total_distance_error / total_samples\n",
    "    print(f'Average keypoint distance error: {avg_distance_error:.4f}')\n",
    "    \n",
    "    return avg_distance_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb712a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 92 samples\n"
     ]
    }
   ],
   "source": [
    "JSON_FILE = 'knee_annotations/7-2-25/knee_points_4_5_flipped.json'\n",
    "STL_DIR = 'scans_3/'\n",
    "MODEL_SAVE_PATH = 'kp-selector-1.pth'\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = KneeKeypointDataset(\n",
    "    json_file=JSON_FILE,\n",
    "    pointcloud_dir=STL_DIR,\n",
    "    max_points=MAX_POINTS,\n",
    "    surface_sampling_method=SURFACE_SAMPLING_METHOD,\n",
    "    num_keypoints=NUM_KEYPOINTS\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
    "#print(f\"Using {NUM_KEYPOINTS} keypoints: {dataset.keypoint_names}\") #Defunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd1575d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 73, Validation samples: 19\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86405714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1,391,618 parameters\n",
      "Training on device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = KneeKeypointModel(num_keypoints=NUM_KEYPOINTS)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model has {total_params:,} parameters\")\n",
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Training on device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0fc07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "BATCH_SIZE = 16\n",
    "MAX_POINTS = 8192\n",
    "NUM_KEYPOINTS = 2  \n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 200\n",
    "TRAIN_SPLIT = 0.8\n",
    "SURFACE_SAMPLING_METHOD = 'uniform'  # uniform/poisson\n",
    "\n",
    "# Focal loss hyperparam\n",
    "FOCAL_ALPHA = 1.0\n",
    "FOCAL_GAMMA = 2.0\n",
    "WEIGHT_DECAY = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f43f44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming Training From Checkpoint Saved at:  Checkpoints/checkpoint-1.pth\n",
      "Loading Checkpoint with best val loss:  5.858627796173096\n",
      "[INFO] Resumed training from epoch 34\n",
      "Epoch [34/200] Batch [0] Loss: 5.0415\n",
      "Epoch [34/200] Train Loss: 5.1113 | Val Loss: 6.0056\n",
      "Epoch [35/200] Batch [0] Loss: 4.7832\n",
      "Epoch [35/200] Train Loss: 4.7589 | Val Loss: 6.1259\n",
      "Epoch [36/200] Batch [0] Loss: 4.5543\n",
      "Epoch [36/200] Train Loss: 4.9222 | Val Loss: 6.4147\n",
      "Epoch [37/200] Batch [0] Loss: 4.7836\n",
      "Epoch [37/200] Train Loss: 4.5800 | Val Loss: 6.2031\n",
      "Epoch [38/200] Batch [0] Loss: 4.5194\n",
      "Epoch [38/200] Train Loss: 4.7765 | Val Loss: 6.2109\n",
      "Epoch [39/200] Batch [0] Loss: 4.5774\n",
      "Epoch [39/200] Train Loss: 4.5285 | Val Loss: 6.4493\n",
      "Epoch [40/200] Batch [0] Loss: 4.9143\n",
      "Epoch [40/200] Train Loss: 4.7642 | Val Loss: 5.9857\n",
      "Epoch [41/200] Batch [0] Loss: 4.2307\n",
      "Epoch [41/200] Train Loss: 4.4736 | Val Loss: 5.9712\n",
      "Epoch [42/200] Batch [0] Loss: 4.6682\n",
      "Epoch [42/200] Train Loss: 4.4881 | Val Loss: 6.2509\n",
      "Epoch [43/200] Batch [0] Loss: 4.4735\n",
      "Epoch [43/200] Train Loss: 4.7665 | Val Loss: 6.4596\n",
      "Epoch [44/200] Batch [0] Loss: 4.0203\n",
      "Epoch [44/200] Train Loss: 4.1966 | Val Loss: 5.9917\n",
      "Epoch [45/200] Batch [0] Loss: 5.0902\n",
      "Epoch [45/200] Train Loss: 4.4599 | Val Loss: 6.0386\n",
      "Epoch [46/200] Batch [0] Loss: 4.0065\n",
      "Epoch [46/200] Train Loss: 4.2416 | Val Loss: 6.5173\n",
      "Epoch [47/200] Batch [0] Loss: 4.1122\n",
      "Epoch [47/200] Train Loss: 4.2516 | Val Loss: 6.7572\n",
      "Epoch [48/200] Batch [0] Loss: 3.8571\n",
      "Epoch [48/200] Train Loss: 4.5670 | Val Loss: 6.6125\n",
      "Epoch [49/200] Batch [0] Loss: 4.0109\n",
      "Epoch [49/200] Train Loss: 4.2320 | Val Loss: 6.7103\n",
      "Epoch [50/200] Batch [0] Loss: 3.8829\n",
      "Epoch [50/200] Train Loss: 4.1052 | Val Loss: 6.5220\n",
      "Epoch [51/200] Batch [0] Loss: 3.6019\n",
      "Epoch [51/200] Train Loss: 4.1664 | Val Loss: 6.6991\n",
      "Epoch [52/200] Batch [0] Loss: 3.9669\n",
      "Epoch [52/200] Train Loss: 4.0671 | Val Loss: 6.9345\n",
      "Epoch [53/200] Batch [0] Loss: 4.1158\n",
      "Epoch [53/200] Train Loss: 4.1167 | Val Loss: 6.5849\n",
      "Epoch [54/200] Batch [0] Loss: 3.8343\n",
      "Epoch [54/200] Train Loss: 3.9380 | Val Loss: 6.2027\n",
      "Epoch [55/200] Batch [0] Loss: 3.7303\n",
      "Epoch [55/200] Train Loss: 4.1914 | Val Loss: 6.4494\n",
      "Epoch [56/200] Batch [0] Loss: 4.3773\n",
      "Epoch [56/200] Train Loss: 4.1299 | Val Loss: 6.6555\n",
      "Epoch [57/200] Batch [0] Loss: 4.0718\n",
      "Epoch [57/200] Train Loss: 4.1799 | Val Loss: 6.4968\n",
      "Epoch [58/200] Batch [0] Loss: 4.0939\n",
      "Epoch [58/200] Train Loss: 4.0468 | Val Loss: 6.6861\n",
      "Epoch [59/200] Batch [0] Loss: 4.1470\n",
      "Epoch [59/200] Train Loss: 4.0719 | Val Loss: 6.6289\n",
      "Epoch [60/200] Batch [0] Loss: 4.1884\n",
      "Epoch [60/200] Train Loss: 4.0754 | Val Loss: 6.5446\n",
      "Epoch [61/200] Batch [0] Loss: 3.8874\n",
      "Epoch [61/200] Train Loss: 3.7240 | Val Loss: 6.5983\n",
      "Epoch [62/200] Batch [0] Loss: 3.9662\n",
      "Epoch [62/200] Train Loss: 3.9951 | Val Loss: 6.8440\n",
      "Epoch [63/200] Batch [0] Loss: 3.9548\n",
      "Epoch [63/200] Train Loss: 3.7464 | Val Loss: 6.8722\n",
      "Epoch [64/200] Batch [0] Loss: 3.8775\n",
      "Epoch [64/200] Train Loss: 3.9161 | Val Loss: 6.7073\n",
      "Epoch [65/200] Batch [0] Loss: 3.6507\n",
      "Epoch [65/200] Train Loss: 3.6997 | Val Loss: 6.5303\n",
      "Epoch [66/200] Batch [0] Loss: 4.2124\n",
      "Epoch [66/200] Train Loss: 3.9237 | Val Loss: 6.6674\n",
      "Epoch [67/200] Batch [0] Loss: 3.7809\n",
      "Epoch [67/200] Train Loss: 3.7465 | Val Loss: 6.4951\n",
      "Epoch [68/200] Batch [0] Loss: 3.4520\n",
      "Epoch [68/200] Train Loss: 3.6012 | Val Loss: 6.5858\n",
      "Epoch [69/200] Batch [0] Loss: 3.8024\n",
      "Epoch [69/200] Train Loss: 3.4032 | Val Loss: 6.6462\n",
      "Epoch [70/200] Batch [0] Loss: 3.5360\n",
      "Epoch [70/200] Train Loss: 3.5764 | Val Loss: 6.5156\n",
      "Epoch [71/200] Batch [0] Loss: 3.3519\n",
      "Epoch [71/200] Train Loss: 3.4795 | Val Loss: 6.3246\n",
      "Epoch [72/200] Batch [0] Loss: 3.6181\n",
      "Epoch [72/200] Train Loss: 3.5769 | Val Loss: 6.6321\n",
      "Epoch [73/200] Batch [0] Loss: 4.0465\n",
      "Epoch [73/200] Train Loss: 3.5287 | Val Loss: 6.9544\n",
      "Epoch [74/200] Batch [0] Loss: 3.3240\n",
      "Epoch [74/200] Train Loss: 3.3786 | Val Loss: 7.0122\n",
      "Epoch [75/200] Batch [0] Loss: 3.6676\n",
      "Epoch [75/200] Train Loss: 3.4880 | Val Loss: 7.1997\n",
      "Epoch [76/200] Batch [0] Loss: 3.0940\n",
      "Epoch [76/200] Train Loss: 3.4127 | Val Loss: 7.0576\n",
      "Epoch [77/200] Batch [0] Loss: 3.3264\n",
      "Epoch [77/200] Train Loss: 3.4150 | Val Loss: 6.5484\n",
      "Epoch [78/200] Batch [0] Loss: 3.4287\n",
      "Epoch [78/200] Train Loss: 3.4009 | Val Loss: 6.4832\n",
      "Epoch [79/200] Batch [0] Loss: 3.1681\n",
      "Epoch [79/200] Train Loss: 3.2995 | Val Loss: 6.7745\n",
      "Epoch [80/200] Batch [0] Loss: 3.6948\n",
      "Epoch [80/200] Train Loss: 3.3083 | Val Loss: 6.6603\n",
      "Epoch [81/200] Batch [0] Loss: 3.1410\n",
      "Epoch [81/200] Train Loss: 3.4973 | Val Loss: 6.9432\n",
      "Epoch [82/200] Batch [0] Loss: 3.4042\n",
      "Epoch [82/200] Train Loss: 3.1854 | Val Loss: 6.7255\n",
      "Epoch [83/200] Batch [0] Loss: 3.3789\n",
      "Epoch [83/200] Train Loss: 3.3824 | Val Loss: 6.2245\n",
      "Epoch [84/200] Batch [0] Loss: 3.2436\n",
      "Epoch [84/200] Train Loss: 3.2308 | Val Loss: 6.4789\n",
      "Epoch [85/200] Batch [0] Loss: 3.4080\n",
      "Epoch [85/200] Train Loss: 3.1950 | Val Loss: 6.2685\n",
      "Epoch [86/200] Batch [0] Loss: 3.3268\n",
      "Epoch [86/200] Train Loss: 3.5788 | Val Loss: 6.2419\n",
      "Epoch [87/200] Batch [0] Loss: 2.8020\n",
      "Epoch [87/200] Train Loss: 3.3397 | Val Loss: 6.4046\n",
      "Epoch [88/200] Batch [0] Loss: 3.3189\n",
      "Epoch [88/200] Train Loss: 3.4747 | Val Loss: 6.4961\n",
      "Epoch [89/200] Batch [0] Loss: 3.6229\n",
      "Epoch [89/200] Train Loss: 3.3482 | Val Loss: 6.5555\n",
      "Epoch [90/200] Batch [0] Loss: 3.1073\n",
      "Epoch [90/200] Train Loss: 3.1715 | Val Loss: 6.7230\n",
      "Epoch [91/200] Batch [0] Loss: 3.4892\n",
      "Epoch [91/200] Train Loss: 3.4105 | Val Loss: 7.4233\n",
      "Epoch [92/200] Batch [0] Loss: 3.5250\n",
      "Epoch [92/200] Train Loss: 3.4358 | Val Loss: 6.9900\n",
      "Epoch [93/200] Batch [0] Loss: 2.9826\n",
      "Epoch [93/200] Train Loss: 3.2014 | Val Loss: 6.8015\n",
      "Epoch [94/200] Batch [0] Loss: 3.3727\n",
      "Epoch [94/200] Train Loss: 3.3576 | Val Loss: 6.6665\n",
      "Epoch [95/200] Batch [0] Loss: 3.4039\n",
      "Epoch [95/200] Train Loss: 3.3265 | Val Loss: 6.6155\n",
      "Epoch [96/200] Batch [0] Loss: 3.3204\n",
      "Epoch [96/200] Train Loss: 3.2799 | Val Loss: 6.9611\n",
      "Epoch [97/200] Batch [0] Loss: 3.3815\n",
      "Epoch [97/200] Train Loss: 2.9968 | Val Loss: 6.9451\n",
      "Epoch [98/200] Batch [0] Loss: 3.0434\n",
      "Epoch [98/200] Train Loss: 2.9771 | Val Loss: 7.0565\n",
      "Epoch [99/200] Batch [0] Loss: 3.0428\n",
      "Epoch [99/200] Train Loss: 2.9277 | Val Loss: 6.8271\n",
      "Epoch [100/200] Batch [0] Loss: 3.0111\n",
      "Epoch [100/200] Train Loss: 3.1665 | Val Loss: 6.8660\n",
      "Epoch [101/200] Batch [0] Loss: 3.2192\n",
      "Epoch [101/200] Train Loss: 3.0887 | Val Loss: 6.9414\n",
      "Epoch [102/200] Batch [0] Loss: 3.0527\n",
      "Epoch [102/200] Train Loss: 3.1082 | Val Loss: 6.7544\n",
      "Epoch [103/200] Batch [0] Loss: 3.0385\n",
      "Epoch [103/200] Train Loss: 2.8764 | Val Loss: 6.7156\n",
      "Epoch [104/200] Batch [0] Loss: 3.1278\n",
      "Epoch [104/200] Train Loss: 2.9392 | Val Loss: 6.6041\n",
      "Epoch [105/200] Batch [0] Loss: 2.8957\n",
      "Epoch [105/200] Train Loss: 3.0309 | Val Loss: 6.7255\n",
      "Epoch [106/200] Batch [0] Loss: 3.2400\n",
      "Epoch [106/200] Train Loss: 2.8628 | Val Loss: 6.8193\n",
      "Epoch [107/200] Batch [0] Loss: 3.1062\n",
      "Epoch [107/200] Train Loss: 2.9848 | Val Loss: 6.8513\n",
      "Epoch [108/200] Batch [0] Loss: 3.0177\n",
      "Epoch [108/200] Train Loss: 2.9370 | Val Loss: 6.9484\n",
      "Epoch [109/200] Batch [0] Loss: 2.9002\n",
      "Epoch [109/200] Train Loss: 2.8475 | Val Loss: 6.9337\n",
      "Epoch [110/200] Batch [0] Loss: 2.5731\n",
      "Epoch [110/200] Train Loss: 2.7788 | Val Loss: 6.9467\n",
      "Epoch [111/200] Batch [0] Loss: 2.8462\n",
      "Epoch [111/200] Train Loss: 2.8892 | Val Loss: 6.8109\n",
      "Epoch [112/200] Batch [0] Loss: 2.8089\n",
      "Epoch [112/200] Train Loss: 2.8877 | Val Loss: 6.9094\n",
      "Epoch [113/200] Batch [0] Loss: 2.6851\n",
      "Epoch [113/200] Train Loss: 2.8944 | Val Loss: 7.0231\n",
      "Epoch [114/200] Batch [0] Loss: 2.8276\n",
      "Epoch [114/200] Train Loss: 2.9823 | Val Loss: 6.8209\n",
      "Epoch [115/200] Batch [0] Loss: 3.4311\n",
      "Epoch [115/200] Train Loss: 2.9213 | Val Loss: 6.8770\n",
      "Epoch [116/200] Batch [0] Loss: 3.1595\n",
      "Epoch [116/200] Train Loss: 2.8585 | Val Loss: 6.7261\n",
      "Epoch [117/200] Batch [0] Loss: 2.8946\n",
      "Epoch [117/200] Train Loss: 3.1874 | Val Loss: 7.0506\n",
      "Epoch [118/200] Batch [0] Loss: 2.8890\n",
      "Epoch [118/200] Train Loss: 2.9018 | Val Loss: 7.1032\n",
      "Epoch [119/200] Batch [0] Loss: 3.1698\n",
      "Epoch [119/200] Train Loss: 2.8235 | Val Loss: 7.0598\n",
      "Epoch [120/200] Batch [0] Loss: 2.7898\n",
      "Epoch [120/200] Train Loss: 2.7716 | Val Loss: 7.0615\n",
      "Epoch [121/200] Batch [0] Loss: 2.9688\n",
      "Epoch [121/200] Train Loss: 2.8450 | Val Loss: 7.2418\n",
      "Epoch [122/200] Batch [0] Loss: 3.1780\n",
      "Epoch [122/200] Train Loss: 3.1214 | Val Loss: 7.1864\n",
      "Epoch [123/200] Batch [0] Loss: 2.7327\n",
      "Epoch [123/200] Train Loss: 2.7732 | Val Loss: 7.1946\n",
      "Epoch [124/200] Batch [0] Loss: 3.0946\n",
      "Epoch [124/200] Train Loss: 2.7918 | Val Loss: 7.1365\n",
      "Epoch [125/200] Batch [0] Loss: 2.9634\n",
      "Epoch [125/200] Train Loss: 2.9428 | Val Loss: 7.1830\n",
      "Epoch [126/200] Batch [0] Loss: 2.4881\n",
      "Epoch [126/200] Train Loss: 2.7881 | Val Loss: 7.0352\n",
      "Epoch [127/200] Batch [0] Loss: 2.7710\n",
      "Epoch [127/200] Train Loss: 2.5307 | Val Loss: 7.0122\n",
      "Epoch [128/200] Batch [0] Loss: 2.6051\n",
      "Epoch [128/200] Train Loss: 2.7040 | Val Loss: 6.7852\n",
      "Epoch [129/200] Batch [0] Loss: 2.5327\n",
      "Epoch [129/200] Train Loss: 2.7714 | Val Loss: 7.0256\n",
      "Epoch [130/200] Batch [0] Loss: 2.6907\n",
      "Epoch [130/200] Train Loss: 2.7751 | Val Loss: 7.0111\n",
      "Epoch [131/200] Batch [0] Loss: 3.1635\n",
      "Epoch [131/200] Train Loss: 2.9316 | Val Loss: 6.8800\n",
      "Epoch [132/200] Batch [0] Loss: 2.5545\n",
      "Epoch [132/200] Train Loss: 2.6397 | Val Loss: 6.9559\n",
      "Epoch [133/200] Batch [0] Loss: 2.5484\n",
      "Epoch [133/200] Train Loss: 2.8344 | Val Loss: 7.0696\n",
      "Epoch [134/200] Batch [0] Loss: 2.3856\n",
      "Epoch [134/200] Train Loss: 2.6485 | Val Loss: 7.1596\n",
      "Epoch [135/200] Batch [0] Loss: 2.7802\n",
      "Epoch [135/200] Train Loss: 2.9020 | Val Loss: 7.0885\n",
      "Epoch [136/200] Batch [0] Loss: 2.5120\n",
      "Epoch [136/200] Train Loss: 2.6219 | Val Loss: 7.0117\n",
      "Epoch [137/200] Batch [0] Loss: 2.6550\n",
      "Epoch [137/200] Train Loss: 2.5331 | Val Loss: 6.9723\n",
      "Epoch [138/200] Batch [0] Loss: 2.2801\n",
      "Epoch [138/200] Train Loss: 2.6856 | Val Loss: 6.9733\n",
      "Epoch [139/200] Batch [0] Loss: 2.9490\n",
      "Epoch [139/200] Train Loss: 2.5782 | Val Loss: 6.8814\n",
      "Epoch [140/200] Batch [0] Loss: 2.4119\n",
      "Epoch [140/200] Train Loss: 2.7797 | Val Loss: 7.1561\n",
      "Epoch [141/200] Batch [0] Loss: 2.7869\n",
      "Epoch [141/200] Train Loss: 2.6470 | Val Loss: 7.0197\n",
      "Epoch [142/200] Batch [0] Loss: 2.2132\n",
      "Epoch [142/200] Train Loss: 2.4376 | Val Loss: 6.9210\n",
      "Epoch [143/200] Batch [0] Loss: 2.4622\n",
      "Epoch [143/200] Train Loss: 2.4094 | Val Loss: 7.0262\n",
      "Epoch [144/200] Batch [0] Loss: 2.2430\n",
      "Epoch [144/200] Train Loss: 2.7570 | Val Loss: 6.9539\n",
      "Epoch [145/200] Batch [0] Loss: 2.9181\n",
      "Epoch [145/200] Train Loss: 2.8691 | Val Loss: 6.9011\n",
      "Epoch [146/200] Batch [0] Loss: 2.6146\n",
      "Epoch [146/200] Train Loss: 2.5722 | Val Loss: 7.1738\n",
      "Epoch [147/200] Batch [0] Loss: 2.4809\n",
      "Epoch [147/200] Train Loss: 2.6334 | Val Loss: 7.2022\n",
      "Epoch [148/200] Batch [0] Loss: 2.7647\n",
      "Epoch [148/200] Train Loss: 2.7502 | Val Loss: 7.0273\n",
      "Epoch [149/200] Batch [0] Loss: 3.1026\n",
      "Epoch [149/200] Train Loss: 2.7576 | Val Loss: 6.9151\n",
      "Epoch [150/200] Batch [0] Loss: 2.7009\n",
      "Epoch [150/200] Train Loss: 2.6588 | Val Loss: 6.9625\n",
      "Epoch [151/200] Batch [0] Loss: 2.7853\n",
      "Epoch [151/200] Train Loss: 2.4765 | Val Loss: 6.9668\n",
      "Epoch [152/200] Batch [0] Loss: 2.7792\n",
      "Epoch [152/200] Train Loss: 2.6697 | Val Loss: 6.9850\n",
      "Epoch [153/200] Batch [0] Loss: 2.8167\n",
      "Epoch [153/200] Train Loss: 2.5793 | Val Loss: 7.0364\n",
      "Epoch [154/200] Batch [0] Loss: 2.5867\n",
      "Epoch [154/200] Train Loss: 2.8528 | Val Loss: 7.0464\n",
      "Epoch [155/200] Batch [0] Loss: 2.8129\n",
      "Epoch [155/200] Train Loss: 2.6821 | Val Loss: 7.0570\n",
      "Epoch [156/200] Batch [0] Loss: 2.7420\n",
      "Epoch [156/200] Train Loss: 2.4728 | Val Loss: 7.1196\n",
      "Epoch [157/200] Batch [0] Loss: 2.7549\n",
      "Epoch [157/200] Train Loss: 2.6869 | Val Loss: 7.1279\n",
      "Epoch [158/200] Batch [0] Loss: 2.7510\n",
      "Epoch [158/200] Train Loss: 2.5867 | Val Loss: 7.0460\n",
      "Epoch [159/200] Batch [0] Loss: 2.4182\n",
      "Epoch [159/200] Train Loss: 2.4789 | Val Loss: 7.0743\n",
      "Epoch [160/200] Batch [0] Loss: 2.1836\n",
      "Epoch [160/200] Train Loss: 2.3666 | Val Loss: 7.1566\n",
      "Epoch [161/200] Batch [0] Loss: 2.6186\n",
      "Epoch [161/200] Train Loss: 2.4001 | Val Loss: 7.2000\n",
      "Epoch [162/200] Batch [0] Loss: 2.4931\n",
      "Epoch [162/200] Train Loss: 2.5485 | Val Loss: 7.1919\n",
      "Epoch [163/200] Batch [0] Loss: 2.7500\n",
      "Epoch [163/200] Train Loss: 2.7330 | Val Loss: 7.0852\n",
      "Epoch [164/200] Batch [0] Loss: 2.5363\n",
      "Epoch [164/200] Train Loss: 2.5255 | Val Loss: 6.9614\n",
      "Epoch [165/200] Batch [0] Loss: 2.7365\n",
      "Epoch [165/200] Train Loss: 2.6747 | Val Loss: 7.0181\n",
      "Epoch [166/200] Batch [0] Loss: 2.6389\n",
      "Epoch [166/200] Train Loss: 2.4623 | Val Loss: 7.0980\n",
      "Epoch [167/200] Batch [0] Loss: 2.6537\n",
      "Epoch [167/200] Train Loss: 2.4856 | Val Loss: 7.1248\n",
      "Epoch [168/200] Batch [0] Loss: 2.3585\n",
      "Epoch [168/200] Train Loss: 2.6210 | Val Loss: 7.0523\n",
      "Epoch [169/200] Batch [0] Loss: 2.2489\n",
      "Epoch [169/200] Train Loss: 2.5233 | Val Loss: 7.1060\n",
      "Epoch [170/200] Batch [0] Loss: 2.3447\n",
      "Epoch [170/200] Train Loss: 2.5881 | Val Loss: 7.1789\n",
      "Epoch [171/200] Batch [0] Loss: 2.6103\n",
      "Epoch [171/200] Train Loss: 2.5946 | Val Loss: 7.1327\n",
      "Epoch [172/200] Batch [0] Loss: 2.7201\n",
      "Epoch [172/200] Train Loss: 2.4530 | Val Loss: 7.0965\n",
      "Epoch [173/200] Batch [0] Loss: 2.6918\n",
      "Epoch [173/200] Train Loss: 2.6547 | Val Loss: 7.1969\n",
      "Epoch [174/200] Batch [0] Loss: 2.2289\n",
      "Epoch [174/200] Train Loss: 2.4765 | Val Loss: 7.1864\n",
      "Epoch [175/200] Batch [0] Loss: 2.9900\n",
      "Epoch [175/200] Train Loss: 2.9289 | Val Loss: 7.0526\n",
      "Epoch [176/200] Batch [0] Loss: 2.3710\n",
      "Epoch [176/200] Train Loss: 2.5878 | Val Loss: 6.9580\n",
      "Epoch [177/200] Batch [0] Loss: 2.9389\n",
      "Epoch [177/200] Train Loss: 2.5666 | Val Loss: 6.9694\n",
      "Epoch [178/200] Batch [0] Loss: 2.3260\n",
      "Epoch [178/200] Train Loss: 2.3937 | Val Loss: 7.0661\n",
      "Epoch [179/200] Batch [0] Loss: 2.3714\n",
      "Epoch [179/200] Train Loss: 2.7776 | Val Loss: 7.1070\n",
      "Epoch [180/200] Batch [0] Loss: 1.9692\n",
      "Epoch [180/200] Train Loss: 2.2916 | Val Loss: 6.9037\n",
      "Epoch [181/200] Batch [0] Loss: 3.1461\n",
      "Epoch [181/200] Train Loss: 2.7034 | Val Loss: 7.0896\n",
      "Epoch [182/200] Batch [0] Loss: 3.2173\n",
      "Epoch [182/200] Train Loss: 2.6013 | Val Loss: 7.0273\n",
      "Epoch [183/200] Batch [0] Loss: 1.8899\n",
      "Epoch [183/200] Train Loss: 2.4970 | Val Loss: 7.1310\n",
      "Epoch [184/200] Batch [0] Loss: 2.2241\n",
      "Epoch [184/200] Train Loss: 2.4289 | Val Loss: 6.9393\n",
      "Epoch [185/200] Batch [0] Loss: 2.6323\n",
      "Epoch [185/200] Train Loss: 2.4602 | Val Loss: 7.0220\n",
      "Epoch [186/200] Batch [0] Loss: 2.2762\n",
      "Epoch [186/200] Train Loss: 2.5286 | Val Loss: 7.1304\n",
      "Epoch [187/200] Batch [0] Loss: 2.4988\n",
      "Epoch [187/200] Train Loss: 2.3843 | Val Loss: 7.0745\n",
      "Epoch [188/200] Batch [0] Loss: 2.4233\n",
      "Epoch [188/200] Train Loss: 2.2991 | Val Loss: 7.1090\n",
      "Epoch [189/200] Batch [0] Loss: 2.3359\n",
      "Epoch [189/200] Train Loss: 2.2815 | Val Loss: 7.1181\n",
      "Epoch [190/200] Batch [0] Loss: 2.4488\n",
      "Epoch [190/200] Train Loss: 2.4983 | Val Loss: 7.1101\n",
      "Epoch [191/200] Batch [0] Loss: 2.3108\n",
      "Epoch [191/200] Train Loss: 2.6257 | Val Loss: 7.1628\n",
      "Epoch [192/200] Batch [0] Loss: 2.3320\n",
      "Epoch [192/200] Train Loss: 2.5476 | Val Loss: 7.1359\n",
      "Epoch [193/200] Batch [0] Loss: 2.5755\n",
      "Epoch [193/200] Train Loss: 2.6112 | Val Loss: 7.1710\n",
      "Epoch [194/200] Batch [0] Loss: 2.3512\n",
      "Epoch [194/200] Train Loss: 2.4773 | Val Loss: 7.1273\n",
      "Epoch [195/200] Batch [0] Loss: 2.3056\n",
      "Epoch [195/200] Train Loss: 2.4210 | Val Loss: 7.1640\n",
      "Epoch [196/200] Batch [0] Loss: 1.8754\n",
      "Epoch [196/200] Train Loss: 2.4590 | Val Loss: 7.1362\n",
      "Epoch [197/200] Batch [0] Loss: 1.9934\n",
      "Epoch [197/200] Train Loss: 2.5804 | Val Loss: 6.9996\n",
      "Epoch [198/200] Batch [0] Loss: 2.7398\n",
      "Epoch [198/200] Train Loss: 2.5829 | Val Loss: 7.1091\n",
      "Epoch [199/200] Batch [0] Loss: 2.3226\n",
      "Epoch [199/200] Train Loss: 2.3342 | Val Loss: 7.0800\n",
      "[INFO] Training completed. Best model loaded from kp-selector-1.pth\n",
      "Average keypoint distance error: 0.1117\n",
      "Final evaluation - Average keypoint distance error: 0.1117\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=device,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    focal_alpha=FOCAL_ALPHA,\n",
    "    focal_gamma=FOCAL_GAMMA,\n",
    "    save_path='kp-selector-1.pth',\n",
    "    checkpoint_path='Checkpoints/checkpoint-1.pth',\n",
    "    load_path = 'Checkpoints/checkpoint-1.pth',\n",
    "    resume=True \n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "avg_error = evaluate_model(trained_model, val_loader, device=device)\n",
    "print(f\"Final evaluation - Average keypoint distance error: {avg_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19eba496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed! Hyperparameters saved to hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "# Save hyperparameters for reference\n",
    "hyperparams = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'max_points': MAX_POINTS,\n",
    "    'num_keypoints': NUM_KEYPOINTS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'focal_alpha': FOCAL_ALPHA,\n",
    "    'focal_gamma': FOCAL_GAMMA,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "    'surface_sampling_method': SURFACE_SAMPLING_METHOD\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('hyperparameters.json', 'w') as f:\n",
    "    json.dump(hyperparams, f, indent=2)\n",
    "\n",
    "print(\"Training completed! Hyperparameters saved to hyperparameters.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2698b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4fb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current checkpoint every epoch\n",
    "checkpoint_path = 'checkpoint.pth'\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'best_val_loss': best_val_loss\n",
    "}\n",
    "torch.save(checkpoint, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ac60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume and os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint['best_val_loss']\n",
    "    print(f\"Resumed training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41aa3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
